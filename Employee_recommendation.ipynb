{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = {\n",
    "      'account': 'cm18591.west-europe.azure',\n",
    "      'user': 'LITINGAALTO',\n",
    "      'password': '199341Asd'\n",
    "      }\n",
    "import pandas as pd\n",
    "from snowflake.sqlalchemy import URL\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "engine = create_engine(URL(\n",
    "            account = sf['account'],\n",
    "            user = sf['user'],\n",
    "            password = sf['password'],\n",
    "            role = 'SYSADMIN',\n",
    "            database = 'SEURE_DM_DEV',\n",
    "            warehouse = 'ANALYTICS_WH',\n",
    "            schema = 'ANALYTIIKKA',\n",
    "            numpy = True\n",
    "        ))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import requests \n",
    "import json \n",
    "import math\n",
    "today=date.today()\n",
    "toimialaid=[ 10, 20, 30, 40, 60, 70, 90, 100]\n",
    "# \"10 Terveydenhuolto, 20 Varhaiskasvatus, 30 Opetus, 40 Sosiaali, 60 Keittiö ja siivous, 70 Kiinteistö ja valvonta,  90 Hallinto- ja toimisto, 100 Muut\"\n",
    "\n",
    "query=f\"select * from VIEW_TOTEUMA_CONFIRM2 where toimiala={toimialaid[0]}\"\n",
    "query1=f\"select tyontekijaid, erityisominaisuusid from staging_test.public.STG_KEIKKANETTI_tblTyontekijaErityisominaisuudet\\\n",
    " where viimeinenvoimassaolopaiva is null or  viimeinenvoimassaolopaiva >='{today}'\"  \n",
    "query2=f\"select * from VIEW_TYO_FEATURE2 where toimiala = {toimialaid[0]}\"\n",
    "query4 ='select osoite, postinumero, postitoimipaikka, tyontekija_id from \"SEURE_DM_PROD\".\"LIIKETOIMINTA_HENKILOTASO\".\"VIEW_D_TYONTEKIJA\"  where KEIKKAILUKELPOINEN = True and (osoite is not null and postinumero is not null)'\n",
    "query5=f\"select distinct asiakasid, tyontekijaid from staging_test.public.STG_KEIKKANETTI_tblTyontekijaSulkulista where tyyppi =2 and \\\n",
    "asiakasid in (select distinct id from  staging_test.public.STG_KEIKKANETTI_tblAsiakas where kustannuspaikkaID = {toimialaid[0]})\"\n",
    "query6='select distinct  tyontekijaid,asiakasid from staging_test.public.STG_KEIKKANETTI_tblTyontekijaSulkulista where tyyppi =1'\n",
    "query7 = \"select * from view_varattu_tyontekjia_today\"\n",
    "query8 = \"select * from view_tyontekija_ammattinimike\"\n",
    "query9 = f\"select * from view_tilaus_lisakriteeri2 where toimiala_id = '{toimialaid[0]}'\"\n",
    "\n",
    "connection = engine.connect()\n",
    "df = pd.read_sql(query, connection)\n",
    "df_employee=pd.read_sql(query1, connection)\n",
    "df_job=pd.read_sql(query2, connection)\n",
    "emp_add = pd.read_sql(query4, connection)\n",
    "asiakas_sulkulista = pd.read_sql(query5, connection)\n",
    "tyontekija_sulkulista = pd.read_sql(query6, connection)\n",
    "emp_varattu= pd.read_sql(query7, connection)\n",
    "emp_amma=pd.read_sql(query8, connection)\n",
    "tilaus_erityisominaisuus= pd.read_sql(query9, connection)\n",
    "emp_amma.nimi = emp_amma.nimi.apply(lambda x: x.strip())\n",
    "tilaus_erityisominaisuus = tilaus_erityisominaisuus.fillna(0)\n",
    "# convert 258 to 351\n",
    "df_employee.loc[df_employee.erityisominaisuusid==258, 'erityisominaisuusid']=351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique employees: 5067, unique_jobs: 1631\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tyontekija_id</th>\n",
       "      <th>job</th>\n",
       "      <th>tyovuorot_taytetyt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>33598</td>\n",
       "      <td>7533;Lähihoitaja, vuodeosasto</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16925</th>\n",
       "      <td>129666</td>\n",
       "      <td>18973;Lähihoitaja, kotihoito</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13395</th>\n",
       "      <td>111459</td>\n",
       "      <td>13776;Lähihoitaja, kotihoito lääkehoitoluvaton</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tyontekija_id                                             job  \\\n",
       "3206           33598                   7533;Lähihoitaja, vuodeosasto   \n",
       "16925         129666                    18973;Lähihoitaja, kotihoito   \n",
       "13395         111459  13776;Lähihoitaja, kotihoito lääkehoitoluvaton   \n",
       "\n",
       "       tyovuorot_taytetyt  \n",
       "3206                  127  \n",
       "16925                 123  \n",
       "13395                 121  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "df['nimi']=df['nimi'].apply(lambda x: str(x).strip())\n",
    "df2019=df[['tyontekijaid','asiakasid','maara','nimi','asiakasnimi','tilausid']]\n",
    "df2019['job']=df2019['asiakasid'].astype(str)+\";\"+df2019['nimi']\n",
    "\n",
    "df2019=df2019.groupby(['tyontekijaid','job'])['maara'].sum().reset_index()\n",
    "df2019.columns=['tyontekija_id','job','tyovuorot_taytetyt']\n",
    "df2019.tyontekija_id=df2019.tyontekija_id.astype(int)\n",
    "df2019 = df2019[df2019['tyovuorot_taytetyt']>0]\n",
    "df2019['tyovuorot_taytetyt']=df2019['tyovuorot_taytetyt'].apply(lambda x: math.ceil(x/7.5))\n",
    "df2019['tyovuorot_taytetyt']=df2019['tyovuorot_taytetyt'].astype(int)\n",
    "n_employees = df2019.tyontekija_id.unique().shape[0]\n",
    "n_jobs = df2019.job.unique().shape[0]\n",
    "print(\"unique employees: {}, unique_jobs: {}\".format(n_employees, n_jobs))\n",
    "df2019.sort_values('tyovuorot_taytetyt', ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the 5% outliers \n",
    "a=df2019.groupby(['tyontekija_id','job']).sum().reset_index().sort_values('tyovuorot_taytetyt',ascending = False)\n",
    "need_scale=a[a['tyovuorot_taytetyt']>a['tyovuorot_taytetyt'].quantile(0.95)]\n",
    "rest = a[a['tyovuorot_taytetyt']<=a['tyovuorot_taytetyt'].quantile(0.95)]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(a['tyovuorot_taytetyt'].quantile(0.95),a['tyovuorot_taytetyt'].quantile(0.95)+8))\n",
    "scaler.fit(need_scale['tyovuorot_taytetyt'].values.reshape(-1,1))\n",
    "need_scale['tyovuorot_taytetyt']=scaler.transform(need_scale['tyovuorot_taytetyt'].values.reshape(-1,1))\n",
    "# append the data with the modified 5%\n",
    "df_scaled=rest.append(need_scale)\n",
    "df_scaled['jobs']=df_scaled['job'].apply(lambda x: str(x).strip())\n",
    "df_scaled['job']=df_scaled['jobs']\n",
    "ratings=df_scaled.pivot_table(index='tyontekija_id', columns='job', values='tyovuorot_taytetyt').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1632 jobs and 61 erityisominaisuusid in tyo_taidot\n"
     ]
    }
   ],
   "source": [
    "# This is the jobs that have orders in past 6kk, terveydenhuolto\n",
    "df_terv=df_job\n",
    "df_terv['job']=df_terv['job'].apply(lambda x: str(x).strip())\n",
    "df['job']=df['asiakasid'].astype(str)+\";\"+df['nimi']\n",
    "\n",
    "terv2019=pd.DataFrame(df.groupby(['tyontekijaid','job'])['maara'].sum()).reset_index()\n",
    "df_terv=terv2019.merge(df_terv[['job', 'katuosoite','postinumero','postitoimipaikka','erityisominaisuusid']], how='left', on='job')\n",
    "a=df_terv[['job', 'erityisominaisuusid']]\n",
    "a.fillna(0, inplace=True)\n",
    "a['arvo']=1\n",
    "tyo_taidot=a.pivot_table(index='job', columns='erityisominaisuusid').fillna(0)\n",
    "tyo_taidot=tyo_taidot['arvo'].drop(0,1)\n",
    "print('there are {} jobs and {} erityisominaisuusid in tyo_taidot'.format(tyo_taidot.shape[0], tyo_taidot.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee(s) that do not have any features: set()\n",
      "there are 54332 employees and 438 erityisominaisuusid in employee feature table\n",
      "filtering only common erityisominaisuusid with job+add missing employees...\n",
      "there are 54332 employees and 61 common erityisominaisuusid in employee feature table\n"
     ]
    }
   ],
   "source": [
    "b=df_employee[['tyontekijaid','erityisominaisuusid']]\n",
    "b['arvo']=1\n",
    "x=b.pivot_table(index='tyontekijaid', columns='erityisominaisuusid').fillna(0)['arvo']\n",
    "c=list(set(tyo_taidot.columns) & set(x.columns))\n",
    "if len(list(set(tyo_taidot.columns)-set(c))) != 0:\n",
    "    print('None of the employees have {} skills as required in jobs'.format(list(set(tyo_taidot.columns)-set(c))))\n",
    "tyo_taidot=tyo_taidot[c]\n",
    "employee_taidot=x[c]\n",
    "#These are the employees that are missing erityisominaisuus\n",
    "bb=set(df.tyontekijaid.unique())- set(employee_taidot.index.tolist())\n",
    "print('Employee(s) that do not have any features: {}'.format(bb))\n",
    "# Add the missing employess to this employee matrix\n",
    "employee_taidot=employee_taidot.append(pd.DataFrame(np.zeros((len(bb),employee_taidot.shape[1])), index=list(set(df.tyontekijaid.unique())- set(employee_taidot.index.tolist())), columns=c))\n",
    "print('there are {} employees and {} erityisominaisuusid in employee feature table'.format(x.shape[0], x.shape[1]))\n",
    "print('filtering only common erityisominaisuusid with job+add missing employees...\\nthere are {} employees and {} common erityisominaisuusid in employee feature table'.format(employee_taidot.shape[0], employee_taidot.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load coordinates for employees and customers & sulkulista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=pd.read_excel('employee_cod.xlsx')\n",
    "xs=xs.drop('Unnamed: 0',1)\n",
    "xs.columns=['tyontekijaid','address','lat','lon']\n",
    "coordinate_dictionary={}\n",
    "for _,i in xs.iterrows():\n",
    "    coordinate_dictionary[i.tyontekijaid]= [i.address, i.lat, i.lon]\n",
    "employee_cod=pd.DataFrame.from_dict(coordinate_dictionary, orient='index')\n",
    "employee_cod.columns=['address','lat','lon']\n",
    "a=pd.read_excel('customer_cod.xlsx')\n",
    "customer_cod=a[['ASIAKAS_ID','katunimi_tulos','x','y' ]].set_index('ASIAKAS_ID')\n",
    "customer_cod.columns=['address','lat','lon']\n",
    "# Make customer dictionary\n",
    "coordinate_dictionary_customer={}\n",
    "for _,i in pd.read_excel('customer_cod.xlsx').iterrows():\n",
    "    coordinate_dictionary_customer[i.ASIAKAS_ID]= [i.x, i.y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "asiakas_sulkulista['arvo']=1\n",
    "asiakas_sulkulista=asiakas_sulkulista.pivot_table(index='asiakasid', columns='tyontekijaid').fillna(0)['arvo']\n",
    "tyontekija_sulkulista['arvo']=1\n",
    "tyontekija_sulkulista=tyontekija_sulkulista.pivot_table(index='tyontekijaid', columns='asiakasid').fillna(0)['arvo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse.linalg import svds\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import statistics\n",
    "import math\n",
    "# Median distance is round to upper int\n",
    "\n",
    "\n",
    "class employee_recommendation:\n",
    "    def __init__(self,  ratings, employee_taidot,tyo_taidot,coordinate_dictionary,\n",
    "                 coordinate_dictionary_customer,tyontekija_sulkulista,  emp_amma):\n",
    "        self.__ratings=ratings\n",
    "        self.__employee_taidot=employee_taidot\n",
    "        self.__tyo_taidot=tyo_taidot\n",
    "        self.__coordinate_dictionary=coordinate_dictionary\n",
    "        self.__coordinate_dictionary_customer=coordinate_dictionary_customer\n",
    "        self.__tyontekija_sulkulista=tyontekija_sulkulista\n",
    "        self.__emp_amma=emp_amma \n",
    "        \n",
    "    def sim_recommendation(self, userid):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :return: recommendation in dataframe format\n",
    "        * if employee did not do gig in past 6kk, then return empty list\n",
    "        \"\"\"\n",
    "        similarities=[]\n",
    "        indices=[]\n",
    "        recommendation=[]\n",
    "        model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute') \n",
    "        model_knn.fit(self.__ratings)\n",
    "        try:\n",
    "            distances, indices = model_knn.kneighbors(self.__ratings.loc[userid].values.reshape(1, -1), n_neighbors = 30)\n",
    "            similarities = 1-distances.flatten()\n",
    "            similarities1=similarities[similarities>=0.5]\n",
    "            if len(similarities1)<2:\n",
    "                recommendation=pd.DataFrame(self.__ratings.loc[userid][self.__ratings.loc[userid]>0]).reset_index()\n",
    "                recommendation.columns=['job','shifts']\n",
    "                return recommendation\n",
    "            else:\n",
    "                x=0\n",
    "                for i in range(len(similarities1)):\n",
    "                    user_i_demean = self.__ratings.iloc[indices[0][i]]\n",
    "                    user_i_cal = user_i_demean * similarities1[i] \n",
    "                    x += user_i_cal\n",
    "                list1=list(zip([j for j in x.values], [j for j in x.index]))\n",
    "                for j in sorted(list1, key = lambda x: x[0], reverse = True)[:30]:\n",
    "                    if j[0]>0:\n",
    "                        recommendation.append((j[1],j[0]))\n",
    "            recommendation=pd.DataFrame(recommendation, columns=['job', 'shifts'])\n",
    "            return recommendation\n",
    "        except:\n",
    "            return []\n",
    "        \n",
    "    \n",
    "    def svd(self):\n",
    "        \"\"\"\n",
    "        :return employee-job matrix with SVD aggregation\n",
    "        \"\"\"\n",
    "        R = self.__ratings.values\n",
    "        user_ratings_mean = np.mean(R, axis = 1)\n",
    "        R_demeaned = R - user_ratings_mean.reshape(-1, 1)\n",
    "        U, sigma, Vt = svds(R_demeaned, k = 50)\n",
    "        sigma = np.diag(sigma)\n",
    "\n",
    "        all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)\n",
    "        preds_df = pd.DataFrame(all_user_predicted_ratings, columns = self.__ratings.columns, index=self.__ratings.index)\n",
    "        a=pd.DataFrame(preds_df.values.astype('int'),columns=preds_df.columns, index=preds_df.index)\n",
    "        return a\n",
    "    \n",
    "    def svd_recommendation(self, userid):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :return: recommendation in dataframe format\n",
    "        * if employee did not do gig in past 6kk, then return empty list\n",
    "        \"\"\"\n",
    "\n",
    "        preds_df=self.svd()\n",
    "        try:\n",
    "            a=pd.DataFrame(preds_df.loc[userid].sort_values(ascending=False)[:30]).reset_index()\n",
    "            x=a[a[userid]>0.5]\n",
    "            x.columns=['job', 'shifts']\n",
    "            if x.shape[0]==0:\n",
    "                return pd.DataFrame(columns=['job','shifts'])\n",
    "            return x\n",
    "        except:\n",
    "            print('This user did not do any jobs in the past 6kk')\n",
    "            return []\n",
    "            \n",
    "    def cf(self,userid, k=10):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :k: number of recommendation shown\n",
    "        return: return combination of KNN and SVD recommendation in dataframe format\n",
    "        * if employee did not do gig in past 6kk, then return empty list\n",
    "        \"\"\"\n",
    "        sim=self.sim_recommendation(userid)\n",
    "        svd=self.svd_recommendation(userid)\n",
    "        try:\n",
    "            svd_job=svd.job.unique().tolist()\n",
    "            sim_job=sim.job.unique().tolist()\n",
    "            common_jobs=(set(svd_job) & set(sim_job))\n",
    "            print('based on historical shift fulfillment, recommendation:\\n')\n",
    "\n",
    "            svd_others=[i for i in list(set(svd_job) - set(common_jobs))]\n",
    "            sim_others=[i for i in list(set(sim_job) - set(svd_job)) ]\n",
    "\n",
    "            b=svd[svd.job.isin(svd_others)].append(sim[sim.job.isin(sim_others)]).sort_values('shifts', ascending=False)\n",
    "            cf_combined=svd[svd.job.isin(common_jobs)].append(b)\n",
    "            if cf_combined.shape[0]<k:\n",
    "                print(cf_combined.job.reset_index().drop('index',1))\n",
    "                return cf_combined.job.reset_index().drop('index',1)\n",
    "            else:\n",
    "                print(cf_combined[:k].job.reset_index().drop('index',1))\n",
    "                return cf_combined[:k].job.reset_index().drop('index',1)\n",
    "        except:\n",
    "            return []\n",
    "        \n",
    "\n",
    "    def validate_skill(self, userid):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :return: validated recommendation from previous step (self.cf) in dataframe format\n",
    "        * if employee did not do gig in past 6kk, then return empty list\n",
    "        \"\"\"\n",
    "        try:\n",
    "            eligible=self.__emp_amma[self.__emp_amma['tyontekijaid']==userid].nimi.unique().tolist()\n",
    "            \n",
    "            xx=self.__employee_taidot.loc[userid].values.reshape(-1,1)\n",
    "            a=self.__tyo_taidot.dot(xx).reset_index()\n",
    "            a['threshold']=self.__tyo_taidot.sum(1).tolist()\n",
    "            a['amma']=a.job.apply(lambda x: x.split(';')[1])\n",
    "            a=a[a['amma'].isin(eligible)]\n",
    "            \n",
    "            return a[a[0]>=a['threshold']].sort_values(0, ascending=False)\n",
    "        except:\n",
    "            print('this employee has no skill and did not do gig in the past 6kk in this industry')\n",
    "            return []\n",
    "\n",
    "   \n",
    "    def calculate_station_distance(self, userid, lon2, lat2 ):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :lon2: longnitude (of each customer)\n",
    "        :lat2: lagnitude (of each customer)\n",
    "        :return: calculated distance between the employee and customers\n",
    "        * if employee address or customer address missing, then return empty list\n",
    "        \"\"\"\n",
    "        try:\n",
    "\n",
    "            lon1 = radians(self.__coordinate_dictionary[userid][2])\n",
    "            lat1 = radians(self.__coordinate_dictionary[userid][1])\n",
    "\n",
    "            a = math.sin(( lat1- lat2) / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin((lon1-lon2) / 2)**2\n",
    "            c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "            distance = 6373 * c\n",
    "            return distance\n",
    "        except:\n",
    "            print(\" Can't find this employee's address!\")\n",
    "            return []\n",
    "\n",
    "\n",
    "    def employee_median_distance(self, userid):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :return: calculated median distance of the employee in past 6 months\n",
    "        \"\"\"\n",
    "        km=[]\n",
    "        a=self.__ratings.loc[userid][self.__ratings.loc[userid]>0]\n",
    "        checklist=pd.DataFrame(a).reset_index().job.apply(lambda x: int(x.split(';')[0]))\n",
    "        for i in checklist:\n",
    "            if i in coordinate_dictionary_customer.keys():\n",
    "                    lat2, lon2= radians(self.__coordinate_dictionary_customer[i][0]), radians(self.__coordinate_dictionary_customer[i][1])\n",
    "                    distance = self.calculate_station_distance(userid, lon2, lat2)\n",
    "                    km.append(distance)\n",
    "        return math.ceil(statistics.median(km))\n",
    "\n",
    "    def content_based(self,userid, km=None):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :km: maximum distance between employee and job, default is None\n",
    "        :return: content-based recommendation in dataframe format within the defined distance (km)\n",
    "        \"\"\"\n",
    "        ok=[]\n",
    "        if km == None:\n",
    "            try:\n",
    "                km=self.employee_median_distance(userid)\n",
    "                print('The median distance of this employee in last 6kk is: {}'.format(km))\n",
    "            except:\n",
    "                km=10\n",
    "        try:\n",
    "            b=self.validate_skill(userid)\n",
    "            for _, i in b.iterrows():\n",
    "                if int(i.job.split(';')[0]) in self.__coordinate_dictionary_customer.keys():\n",
    "                    lat2, lon2= radians(self.__coordinate_dictionary_customer[int(i.job.split(';')[0])][0]), radians(self.__coordinate_dictionary_customer[int(i.job.split(';')[0])][1])\n",
    "                    distance = self.calculate_station_distance(userid, lon2, lat2 )\n",
    "\n",
    "                    if distance <=km:\n",
    "                        ok.append(i.job)\n",
    "            return b[b.job.isin(ok)]\n",
    "        except:\n",
    "            try:\n",
    "                b=self.validate_skill(userid)\n",
    "                return b\n",
    "            except:\n",
    "                b=self.__tyo_taidot[self.__tyo_taidot.sum(1)==0].index.tolist()\n",
    "                eligible=self.__emp_amma[self.__emp_amma['tyontekijaid']==userid].nimi.unique().tolist()\n",
    "                b=[x for x in b if x.split(';')[1] in eligible]\n",
    "                if userid in self.__coordinate_dictionary.keys():\n",
    "                    for i in b:\n",
    "                        if int(i.split(';')[0]) in self.__coordinate_dictionary_customer.keys():\n",
    "                            lat2, lon2= radians(self.__coordinate_dictionary_customer[int(i.split(';')[0])][0]), radians(self.__coordinate_dictionary_customer[int(i.split(';')[0])][1])\n",
    "                            distance = self.calculate_station_distance(userid, lon2, lat2 )\n",
    "                            if distance <=km:\n",
    "                                ok.append(i)\n",
    "                    c=pd.DataFrame(ok, columns=['job'])\n",
    "                    c[0]=0\n",
    "                    c['threshold']=0\n",
    "                    return c\n",
    "                else:\n",
    "                    c=pd.DataFrame(b, columns=['job'])\n",
    "                    c[0]=0\n",
    "                    c['threshold']=0\n",
    "                    return c\n",
    "\n",
    "    def hybrid_recommendation_w_sulku(self,userid, k=10, km=None):\n",
    "        \"\"\"\n",
    "        :userid: employeeid\n",
    "        :k: number of recommendation shown (default: 10)\n",
    "        :km: maximum distance between employee and job, default is None\n",
    "        :return: hybrid recommendation (combining all models) in dataframe format within the defined distance (km)\n",
    "        \"\"\"\n",
    "        sim=self.sim_recommendation(userid)\n",
    "        svd=self.svd_recommendation(userid)\n",
    "        content=self.content_based(userid,km)\n",
    "\n",
    "        try:\n",
    "            svd_job=svd.job.unique().tolist()\n",
    "            sim_job=sim.job.unique().tolist()\n",
    "            common_jobs=(set(svd_job) & set(sim_job))\n",
    "\n",
    "            eligible_common_jobs = [i for i in common_jobs if i in self.validate_skill(userid).job.tolist()]\n",
    "            print('{} recommended jobs for employee {}\\n'.format(k,userid))\n",
    "\n",
    "            svd_others=[i for i in list(set(svd_job) - set(common_jobs)) if i in self.validate_skill(userid).job.tolist()]\n",
    "            sim_others=[i for i in list(set(sim_job) - set(svd_job)) if i in self.validate_skill(userid).job.tolist()]\n",
    "\n",
    "            b=svd[svd.job.isin(svd_others)].append(sim[sim.job.isin(sim_others)]).sort_values('shifts', ascending=False)\n",
    "            if userid not in self.__tyontekija_sulkulista.index.tolist():\n",
    "                cf_combined=svd[svd.job.isin(eligible_common_jobs)].append(b)\n",
    "                if cf_combined.shape[0]<k:\n",
    "                    combined=pd.DataFrame(cf_combined).append(pd.DataFrame(content[:int(k-cf_combined.shape[0])].job)).reset_index().drop('index',1).fillna(0)\n",
    "                    xx=self.__employee_taidot.loc[userid,].values.reshape(-1,1)\n",
    "                    yy=self.__tyo_taidot.loc[combined.job.tolist()]\n",
    "                    a=yy.dot(xx).reset_index()     \n",
    "                    combined['threshold']=a[0]\n",
    "                    b=combined.sort_values(['threshold','shifts'], ascending=False)\n",
    "                    if b.shape[0]>=k:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b[:k].job.reset_index().drop('index',1))\n",
    "                        return b[:k].job.reset_index().drop('index',1)\n",
    "                    else:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b.job.reset_index().drop('index',1))\n",
    "                        return b.job.reset_index().drop('index',1)\n",
    "                else:\n",
    "                    cfc=cf_combined[:int(cf_combined.shape[0]*0.7)]\n",
    "                    combined=cfc.append(pd.DataFrame(content[:min(3,int(cfc.shape[0]/4))].job)).reset_index().drop('index',1).fillna(0)\n",
    "                    xx=self.__employee_taidot.loc[userid,].values.reshape(-1,1)\n",
    "                    yy=self.__tyo_taidot.loc[combined.job.tolist()]\n",
    "                    a=yy.dot(xx).reset_index()   \n",
    "                    combined['threshold']=a[0]\n",
    "                    b=combined.sort_values(['threshold','shifts'], ascending=False)\n",
    "                    if b.shape[0]>=k:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b[:k].job.reset_index().drop('index',1))\n",
    "                        return b[:k].job.reset_index().drop('index',1)\n",
    "                    else:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b.job.reset_index().drop('index',1))\n",
    "                        return b.job.reset_index().drop('index',1)\n",
    "\n",
    "            else:\n",
    "                searchfor =[str(i) for i in self.__tyontekija_sulkulista.loc[userid][self.__tyontekija_sulkulista.loc[userid]>0].index.tolist()]\n",
    "                cf_combined=svd[svd.job.isin(eligible_common_jobs)].append(b)\n",
    "                if cf_combined.shape[0]<k:\n",
    "                    combined=pd.DataFrame(cf_combined).append(pd.DataFrame(content[:int(k-cf_combined.shape[0])].job)).reset_index().drop('index',1).fillna(0)\n",
    "                    xx=self.__employee_taidot.loc[userid,].values.reshape(-1,1)\n",
    "                    yy=self.__tyo_taidot.loc[combined.job.tolist()]\n",
    "                    a=yy.dot(xx).reset_index()   \n",
    "#                     combined['threshold']=a[0]\n",
    "                    combined=combined.merge(a, on='job')[['job','threshold','shifts']]\n",
    "                    b=combined.sort_values(['threshold','shifts'], ascending=False)  \n",
    "                    b=b[~b.job.str.contains('|'.join(searchfor))]\n",
    "                    b=b.sort_values(['threshold','shifts'], ascending=False)\n",
    "                    if b.shape[0]>=k:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b[:k].job.reset_index().drop('index',1).drop_duplicates())\n",
    "                        return b[:k].job.reset_index().drop('index',1).drop_duplicates()\n",
    "                    else:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b.job.reset_index().drop('index',1).drop_duplicates())\n",
    "                        return b.job.reset_index().drop('index',1).drop_duplicates()\n",
    "                else:\n",
    "                    cfc=cf_combined[:int(cf_combined.shape[0]*0.7)]\n",
    "                    combined=cfc.append(pd.DataFrame(content[:min(3,int(cfc.shape[0]/4))].job)).reset_index().drop('index',1).fillna(0)\n",
    "                    xx=self.__employee_taidot.loc[userid,].values.reshape(-1,1)\n",
    "                    yy=self.__tyo_taidot.loc[combined.job.tolist()]\n",
    "                    a=yy.dot(xx).reset_index()  \n",
    "#                     combined['threshold']=a[0]\n",
    "                    combined=combined.merge(a, on='job')[['job','threshold','shifts']]\n",
    "                    b=combined.sort_values(['threshold','shifts'], ascending=False)\n",
    "                    b=b[~b.job.str.contains('|'.join(searchfor))]\n",
    "                    b=b.sort_values(['threshold','shifts'], ascending=False)\n",
    "                    if b.shape[0]>=k:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b[:k].job.reset_index().drop('index',1).drop_duplicates())\n",
    "                        return b[:k].job.reset_index().drop('index',1).drop_duplicates()\n",
    "                    else:\n",
    "                        b=b.drop_duplicates('job')\n",
    "                        print(b.job.reset_index().drop('index',1).drop_duplicates())\n",
    "                        return b.job.reset_index().drop('index',1).drop_duplicates()\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                a=self.content_based(userid,km)\n",
    "                if a.shape[0]>=k:\n",
    "                    print(a[:k].job.reset_index().drop('index',1).drop_duplicates())\n",
    "                    return a[:k].job.reset_index().drop('index',1).drop_duplicates()\n",
    "                else:\n",
    "                    print(b.job.reset_index().drop('index',1).drop_duplicates())\n",
    "                    return b.job.reset_index().drop('index',1).drop_duplicates()\n",
    "            except:\n",
    "                print('failed')\n",
    "                return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=employee_recommendation(ratings, employee_taidot,tyo_taidot,coordinate_dictionary,\n",
    "                 coordinate_dictionary_customer,tyontekija_sulkulista,  emp_amma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median distance of this employee in last 6kk is: 23\n",
      "10 recommended jobs for employee 106\n",
      "\n",
      "                                       job\n",
      "0             5329;Lähihoitaja, vammaistyö\n",
      "1   4850;Lähihoitaja, psykiatria ja päihde\n",
      "2  19355;Lähihoitaja, perusterveydenhuolto\n",
      "3             7845;Lähihoitaja, vammaistyö\n",
      "4             9624;Lähihoitaja, vammaistyö\n",
      "5             5254;Lähihoitaja, vammaistyö\n",
      "6             9204;Lähihoitaja, vammaistyö\n",
      "7            19196;Lähihoitaja, vammaistyö\n",
      "8            10358;Lähihoitaja, vammaistyö\n",
      "9             8980;Lähihoitaja, vammaistyö\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5329;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4850;Lähihoitaja, psykiatria ja päihde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19355;Lähihoitaja, perusterveydenhuolto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7845;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9624;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5254;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9204;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19196;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10358;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8980;Lähihoitaja, vammaistyö</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       job\n",
       "0             5329;Lähihoitaja, vammaistyö\n",
       "1   4850;Lähihoitaja, psykiatria ja päihde\n",
       "2  19355;Lähihoitaja, perusterveydenhuolto\n",
       "3             7845;Lähihoitaja, vammaistyö\n",
       "4             9624;Lähihoitaja, vammaistyö\n",
       "5             5254;Lähihoitaja, vammaistyö\n",
       "6             9204;Lähihoitaja, vammaistyö\n",
       "7            19196;Lähihoitaja, vammaistyö\n",
       "8            10358;Lähihoitaja, vammaistyö\n",
       "9             8980;Lähihoitaja, vammaistyö"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass=a.hybrid_recommendation_w_sulku(106)\n",
    "ass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
